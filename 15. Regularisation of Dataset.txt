15. Regularisation of Dataset

import pandas as pd
import numpy as np
import matplotlib.pyplot as plt
from sklearn import datasets
from sklearn.linear_model import LinearRegression
from sklearn.model_selection import train_test_split
from sklearn.metrics import mean_squared_error, r2_score

boston_dataset = datasets.load_boston()

boston_pd = pd.DataFrame(boston_dataset.data, columns=boston_dataset.feature_names)
boston_pd.head()

boston_pd = pd.DataFrame(boston_dataset.data)
boston_pd_target = np.asarray(boston_dataset.target)

boston_pd['House Price'] = pd.Series(boston_pd_target)

boston_dataset.feature_names

X - boston_pd.iloc[:, :-1]
Y = boston_pd.iloc[:, -1]
print(boston_pd)

x_train, X_test, y_train, y_test = train_test_split(X,Y,test_size=0.25, random_state=0)

lreg = LinearRegression()
lreg.fit(x_train, y_train)
y_pred = lreg.predict(X_test)
LinearRegression(copy_X=True, fit_intercept=True, n_jobs=None, normalize=False)
print("INTERCEPT : ", lreg.intercept_)
print("CO-EFFICIENT : ", lreg.coef_)

y_pred = lreg.predict(X_test)
#calculate R^2 value, MAE, MSE, RMSE

from sklearn import metrics
print("R-Square value", r2_score(y_test, y_pred))
print("\n")
print("mean_absolute_error : ", metrics.mean_absolute_error(y_test, y_pred))
print("\n")
print("mean_squared_error : ",  metrics.mean_squared_error(y_test, y_pred))
print("\n")
print("root_mean_squared_error : ", np.sqrt(metrics.mean_squared_error(y_test, y_pred)))

#Ridge Regression

#create an array of alpha values
alpha_range = 10.**np.arange(-2, 3)
print(alpha_range)
#select the best alpha with RidgeCV
from sklearn.linear_model import RidgeCV
ridgeregcv = RidgeCV(alphas = alpha_range, normalize=True, scoring='neg_mean_squared_error')
ridgeregcv.fit(x_train, y_train)
print(ridgeregcv.alpha_)

#examing the coefficients
print(ridgeregcv.coef_)

#predict method uses the best alpha value
y_pred = ridgeregcv.predict(X_test)
#calculate R^2 value, MAE, MSE, RMSE

from sklearn import metrics
print("R-Square value", r2_score(y_test, y_pred))
print("\n")
print("mean_absolute_error : ", metrics.mean_absolute_error(y_test, y_pred))
print("\n")
print("mean_squared_error : ",  metrics.mean_squared_error(y_test, y_pred))
print("\n")
print("root_mean_squared_error : ", np.sqrt(metrics.mean_squared_error(y_test, y_pred)))

#Lasso Regression

#select the best alpha with LassoCV
from sklearn.linear_model import LassoCV
lassoregcv = LassoCV(n_alpha=100, normalize=True, random_state=1)
lassoregcv.fit(x_train, y_train)
print('alpha : ', lassoregcv.alpha_)

#examine the coefficients
print(lassoregcv.coef_)

#predict method uses the best alpha value
y_pred = lassoregcv.predict(X_test)
#calculate R^2 value, MAE, MSE, RMSE

from sklearn import metrics
print("R-Square value", r2_score(y_test, y_pred))
print("\n")
print("mean_absolute_error : ", metrics.mean_absolute_error(y_test, y_pred))
print("\n")
print("mean_squared_error : ",  metrics.mean_squared_error(y_test, y_pred))
print("\n")
print("root_mean_squared_error : ", np.sqrt(metrics.mean_squared_error(y_test, y_pred)))
